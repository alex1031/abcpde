{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50542637-ee2a-4b9d-ab80-b4932b2b03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_2D(x, y, nx, ny, Lx, Ly, cx, cy, sx, sy):\n",
    "    dx, dy = Lx/(nx-1), Ly/(ny-1)\n",
    "    dt = 1\n",
    "    tend = 1200\n",
    "    t = 0\n",
    "\n",
    "    cfl_x, cfl_y = cx * dt/dx, cy * dt/dy\n",
    "    diff_x, diff_y = sx * dt/dx**2, sy * dt/dy**2\n",
    "\n",
    "    u = np.zeros((nx+2, ny+2))\n",
    "    sol = []\n",
    "    source_x, source_y = nx // 2, ny // 2\n",
    "    # Q = 1e-6\n",
    "    u[source_x, source_y] = 1.0 # Cocentration starts from the central peak\n",
    "    \n",
    "    while t < tend:\n",
    "        unew = u.copy()\n",
    "        sol.append(u[1:-1, 1:-1])\n",
    "\n",
    "         # Advection (Upwind Scheme)\n",
    "        unew[1:-1, 1:-1] -= cfl_x * (u[1:-1, 1:-1] - u[1:-1, :-2])\n",
    "        unew[1:-1, 1:-1] -= cfl_y * (u[1:-1, 1:-1] - u[:-2, 1:-1])\n",
    "    \n",
    "        # Diffusion (Central Differencing)\n",
    "        unew[1:-1, 1:-1] += diff_x * (u[1:-1, 2:] - 2*u[1:-1, 1:-1] + u[1:-1, :-2])\n",
    "        unew[1:-1, 1:-1] += diff_y * (u[2:, 1:-1] - 2*u[1:-1, 1:-1] + u[:-2, 1:-1])\n",
    "\n",
    "        # # Source Term\n",
    "        # unew[source_x, source_y] += Q * dt\n",
    "\n",
    "        # Additional Source Points (forming a small area)\n",
    "        # offsets = [(-1, -1), (-1, 1), (1, -1), (1, 1), (-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "        # for dx, dy in offsets:\n",
    "        #     unew[source_x + dx, source_y + dy] += Q * dt\n",
    "\n",
    "        u = unew\n",
    "        t += dt\n",
    "\n",
    "    '''\n",
    "    We transpose the axis the solution. Such that:\n",
    "    - Axis 0: x\n",
    "    - Axis 1: y\n",
    "    - Axis 2: time\n",
    "    Interpretation: For each x-grid, we have the concentration of each y-grid over time.\n",
    "    Essentially, the (ny, 1200) array represents the concentration at each y over the time.\n",
    "    So we have an array of size 1200 for each y. (A curve)\n",
    "    '''\n",
    "    sol = np.transpose(sol, (1, 2, 0))\n",
    "    return np.array(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561bf313-aab7-41ac-91f1-cc760d3e5df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation took: 2.4931766986846924\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import time as time\n",
    "\n",
    "nx, ny= 51, 51  # Grid points\n",
    "Lx, Ly = 5000, 5000  # Domain size in meters\n",
    "x = np.linspace(-2500, 2500, nx)  # Centered at (0,0)\n",
    "y = np.linspace(-2500, 2500, ny)\n",
    "n = 50\n",
    "cx, cy = np.random.RandomState().uniform(0, 10, n), np.random.RandomState().uniform(0, 10, n)\n",
    "sx, sy = np.random.RandomState().uniform(0, 1, n), np.random.RandomState().uniform(0, 1, n)\n",
    "num_cores = -1\n",
    "\n",
    "start_time = time.time()\n",
    "results = Parallel(n_jobs=num_cores)(\n",
    "    delayed(run_simulation_2D)(x, y, nx, ny, Lx, Ly, cx[i], cy[i], sx[i], sy[i])\n",
    "    for i in range(n)\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Simulation took: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0260ac-bc27-4a0d-88e1-1832d7c90a1d",
   "metadata": {},
   "source": [
    "## Applying Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11775bd9-8afa-4372-82e0-937d8d145434",
   "metadata": {},
   "source": [
    "We try to implement the same way as we have for the 1D problem, and adjust if there are any issues.\n",
    "\n",
    "Because the shape of the results would be in 4D (n, Nx, Ny, time), it would be infeasible to try and solve everything all at once.\n",
    "\n",
    "However, parallelisation can still be utilised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940854b-7f39-47b1-be32-4651b2bb5c87",
   "metadata": {},
   "source": [
    "The distances should be modified such that it computes the distance **for each spatial location** across time first (outputting a 51x51 matrix), with each (i, j) representating the distance at that point, and then output an average (?).\n",
    "\n",
    "The original distance metrics were desgined so that it computes the distance between each column.\n",
    "- This is because each column represented one solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71176d98-5f31-40cc-bd8c-44b9351f6280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 51, 1200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.load(\"test.npy\")\n",
    "observed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7c2eb-c796-4b8f-89b7-6bcbc17e5245",
   "metadata": {},
   "source": [
    "### Wasserstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a38f53-9a4f-44fb-b9f1-7ba163dd025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original ###\n",
    "def wasserstein_distance(simulated_sample: np.ndarray, observed_sample: np.ndarray) -> float:\n",
    "    # Mean Difference between simulated and observed\n",
    "    simulated_sorted = np.sort(simulated_sample, axis=0)\n",
    "    observed_sorted = np.sort(observed_sample, axis=0)\n",
    "    distance = np.mean(np.abs(simulated_sorted - observed_sorted), axis=0)\n",
    "\n",
    "    return distance\n",
    "\n",
    "### Modified ###\n",
    "def wasserstein_distance_3D(simulated_sample: np.ndarray, observed_sample: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the Wasserstein distance between two (51, 51, 1200) shaped arrays \n",
    "    along the time dimension.\n",
    "\n",
    "    Sorted along the time axis, we now have a (51, 51, 1200) array, with each 1200-sized array sorted ascendingly \n",
    "\n",
    "    Returns a (51, 51) array of distances for each spatial location.\n",
    "    \"\"\"\n",
    "    # Sort along the time axis (axis=2)\n",
    "    simulated_sorted = np.sort(simulated_sample, axis=2)\n",
    "    observed_sorted = np.sort(observed_sample, axis=2)\n",
    "\n",
    "    # Compute the mean absolute difference along the time axis\n",
    "    distance = np.mean(np.abs(simulated_sorted - observed_sorted), axis=2)\n",
    "\n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aab4ec6-a642-47a0-9b05-f0aa3d5831eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.141800165176392"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "wass = Parallel(n_jobs=num_cores)(\n",
    "    delayed(wasserstein_distance_3D)(results[i], observed)\n",
    "    for i in range(n)\n",
    ")\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484324f-63ff-4e86-8c5f-406186a7890b",
   "metadata": {},
   "source": [
    "### CvMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b6d26c-8a79-43eb-89bd-86ef2aafa08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Original ###\n",
    "def cramer_von_mises(simulated_sample: np.ndarray, observed_sample: np.ndarray) -> float:\n",
    "    if len(simulated_sample) != len(observed_sample):\n",
    "        return \"Size of samples not equal.\"\n",
    "    \n",
    "    nrow = simulated_sample.shape[0]\n",
    "    ncol = simulated_sample.shape[1]\n",
    "    combined = np.concatenate((simulated_sample, observed_sample))\n",
    "    # Find corresponding ranks in h associated with simulated/observed\n",
    "    combined_rank = np.argsort(combined, axis=0)+1\n",
    "    simulated_rank = combined_rank[:nrow]\n",
    "    observed_rank = combined_rank[nrow:]\n",
    "\n",
    "    # Calculate distance\n",
    "    idx = np.tile(np.arange(1, nrow+1), (ncol, 1)).T\n",
    "    observed_sum = np.sum((observed_rank - idx)**2, axis=0)\n",
    "    simulated_sum = np.sum((simulated_rank - idx)**2, axis=0)\n",
    "    rank_sum = nrow * (observed_sum + simulated_sum)\n",
    "    distance = rank_sum / (2*nrow**3) - (4*nrow**2 - 1)/(12*nrow)\n",
    "\n",
    "    return distance\n",
    "\n",
    "### Modified ###\n",
    "def cramer_von_mises_3d(simulated_sample: np.ndarray, observed_sample: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Outputs a (51, 51), representing CvMD at each grid point.\n",
    "    '''\n",
    "    if simulated_sample.shape != observed_sample.shape:\n",
    "        raise ValueError(\"Shape of samples not equal.\")\n",
    "    \n",
    "    x_dim, y_dim, n_samples = simulated_sample.shape\n",
    "    cvm_matrix = np.zeros((x_dim, y_dim))\n",
    "\n",
    "    # Comparing the (1200,)-shaped array for each (x, y) grid point\n",
    "    for i in range(x_dim):\n",
    "        for j in range(y_dim):\n",
    "            sim = simulated_sample[i, j, :]\n",
    "            obs = observed_sample[i, j, :]\n",
    "\n",
    "            # Combining the two arrays. (2400,)-shaped array\n",
    "            combined = np.concatenate((sim, obs))\n",
    "            # np.argsort(combined) gives us indicies that would sort the combined array in ascending order.\n",
    "            # applying np.argosrt again gives us the rank of each element in the original array.\n",
    "            combined_rank = np.argsort(np.argsort(combined)) + 1\n",
    "\n",
    "            # First half of the combined rank is simulated by definition of combined.\n",
    "            sim_rank = combined_rank[:n_samples]\n",
    "            obs_rank = combined_rank[n_samples:]\n",
    "\n",
    "            # Calculation for CvMD\n",
    "            idx = np.arange(1, n_samples + 1)\n",
    "            obs_sum = np.sum((obs_rank - idx) ** 2)\n",
    "            sim_sum = np.sum((sim_rank - idx) ** 2)\n",
    "            \n",
    "            rank_sum = n_samples * (obs_sum + sim_sum)\n",
    "            distance = rank_sum / (2 * n_samples**3) - (4 * n_samples**2 - 1) / (12 * n_samples)\n",
    "            \n",
    "            cvm_matrix[i, j] = distance\n",
    "    \n",
    "    return cvm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3adaea11-23db-4a62-9b47-d6ea25784bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9667017459869385"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "cvmd = Parallel(n_jobs=num_cores)(\n",
    "    delayed(cramer_von_mises_3d)(results[i], observed)\n",
    "    for i in range(n)\n",
    ")\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50262656-30a4-44a8-87c3-b489f77e1e0e",
   "metadata": {},
   "source": [
    "### Functional Frechet Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269efc9c-c54f-461f-92c8-9fba15d2286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _c(ca, i, j, p, q):\n",
    "\n",
    "    if ca[i, j] > -1:\n",
    "        return ca[i, j]\n",
    "    elif i == 0 and j == 0:\n",
    "        ca[i, j] = np.linalg.norm(p[i]-q[j])\n",
    "    elif i > 0 and j == 0:\n",
    "        ca[i, j] = max(_c(ca, i-1, 0, p, q), np.linalg.norm(p[i]-q[j]))\n",
    "    elif i == 0 and j > 0:\n",
    "        ca[i, j] = max(_c(ca, 0, j-1, p, q), np.linalg.norm(p[i]-q[j]))\n",
    "    elif i > 0 and j > 0:\n",
    "        ca[i, j] = max(\n",
    "            min(\n",
    "                _c(ca, i-1, j, p, q),\n",
    "                _c(ca, i-1, j-1, p, q),\n",
    "                _c(ca, i, j-1, p, q)\n",
    "            ),\n",
    "            np.linalg.norm(p[i]-q[j])\n",
    "            )\n",
    "    else:\n",
    "        ca[i, j] = float('inf')\n",
    "\n",
    "    return ca[i, j]\n",
    "\n",
    "\n",
    "def frdist(p, q):\n",
    "    \"\"\"\n",
    "    Computes the discrete Fréchet distance between\n",
    "    two curves. The Fréchet distance between two curves in a\n",
    "    metric space is a measure of the similarity between the curves.\n",
    "    The discrete Fréchet distance may be used for approximately computing\n",
    "    the Fréchet distance between two arbitrary curves,\n",
    "    as an alternative to using the exact Fréchet distance between a polygonal\n",
    "    approximation of the curves or an approximation of this value.\n",
    "\n",
    "    This is a Python 3.* implementation of the algorithm produced\n",
    "    in Eiter, T. and Mannila, H., 1994. Computing discrete Fréchet distance.\n",
    "    Tech. Report CD-TR 94/64, Information Systems Department, Technical\n",
    "    University of Vienna.\n",
    "    http://www.kr.tuwien.ac.at/staff/eiter/et-archive/cdtr9464.pdf\n",
    "\n",
    "    Function dF(P, Q): real;\n",
    "        input: polygonal curves P = (u1, . . . , up) and Q = (v1, . . . , vq).\n",
    "        return: δdF (P, Q)\n",
    "        ca : array [1..p, 1..q] of real;\n",
    "        function c(i, j): real;\n",
    "            begin\n",
    "                if ca(i, j) > −1 then return ca(i, j)\n",
    "                elsif i = 1 and j = 1 then ca(i, j) := d(u1, v1)\n",
    "                elsif i > 1 and j = 1 then ca(i, j) := max{ c(i − 1, 1), d(ui, v1) }\n",
    "                elsif i = 1 and j > 1 then ca(i, j) := max{ c(1, j − 1), d(u1, vj) }\n",
    "                elsif i > 1 and j > 1 then ca(i, j) :=\n",
    "                max{ min(c(i − 1, j), c(i − 1, j − 1), c(i, j − 1)), d(ui, vj ) }\n",
    "                else ca(i, j) = ∞\n",
    "                return ca(i, j);\n",
    "            end; /* function c */\n",
    "\n",
    "        begin\n",
    "            for i = 1 to p do for j = 1 to q do ca(i, j) := −1.0;\n",
    "            return c(p, q);\n",
    "        end.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : Input curve - two dimensional array of points\n",
    "    Q : Input curve - two dimensional array of points\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dist: float64\n",
    "        The discrete Fréchet distance between curves `P` and `Q`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from frechetdist import frdist\n",
    "    >>> P=[[1,1], [2,1], [2,2]]\n",
    "    >>> Q=[[2,2], [0,1], [2,4]]\n",
    "    >>> frdist(P,Q)\n",
    "    >>> 2.0\n",
    "    >>> P=[[1,1], [2,1], [2,2]]\n",
    "    >>> Q=[[1,1], [2,1], [2,2]]\n",
    "    >>> frdist(P,Q)\n",
    "    >>> 0\n",
    "    \"\"\"\n",
    "    p = np.array(p, np.float64)\n",
    "    q = np.array(q, np.float64)\n",
    "\n",
    "    len_p = len(p)\n",
    "    len_q = len(q)\n",
    "\n",
    "    if len_p == 0 or len_q == 0:\n",
    "        raise ValueError('Input curves are empty.')\n",
    "        \n",
    "    ca = (np.ones((len_p, len_q), dtype=np.float64) * -1)\n",
    "\n",
    "    dist = _c(ca, len_p-1, len_q-1, p, q)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccc064c-995a-4a6b-9729-48541ee11257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.418493032455444\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "frdist(results[0][0, 0], observed[0, 0])\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76355330-a35d-4629-9ada-fe8c65ba5d30",
   "metadata": {},
   "source": [
    "One iteration of this takes ~7.5 seconds, and we have to go through 51x51 of this just for one simulation. The general workflow is to compute the double loops. But this will take too long because it is in $O(nm)$, and in this case $n=m=1200$. \n",
    "\n",
    "One way to reduce computational time is through Downsampling + Parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4eb219d-35c5-4189-981d-8cc3a5f88e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.50614714622498\n",
      "Max Fréchet Distance: 0.6763709617843531\n",
      "Mean Fréchet Distance: 0.0019148486406156734\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import resample\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def frechet_distance_dp(P, Q):\n",
    "    \"\"\"Computes the discrete Fréchet distance using Dynamic Programming.\"\"\"\n",
    "    n, m = len(P), len(Q)\n",
    "    ca = np.full((n, m), np.inf)\n",
    "\n",
    "    ca[0, 0] = np.linalg.norm(P[0] - Q[0])\n",
    "\n",
    "    for i in range(1, n):\n",
    "        ca[i, 0] = max(ca[i - 1, 0], np.linalg.norm(P[i] - Q[0]))\n",
    "    for j in range(1, m):\n",
    "        ca[0, j] = max(ca[0, j - 1], np.linalg.norm(P[0] - Q[j]))\n",
    "\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, m):\n",
    "            ca[i, j] = max(min(ca[i - 1, j], ca[i - 1, j - 1], ca[i, j - 1]), np.linalg.norm(P[i] - Q[j]))\n",
    "\n",
    "    return ca[n - 1, m - 1]\n",
    "\n",
    "# Downsampling function\n",
    "def downsample_trajectory(traj, new_size=300):\n",
    "    \"\"\"Resamples a 1D trajectory to a smaller number of points.\"\"\"\n",
    "    return resample(traj, new_size)\n",
    "\n",
    "# Define the downsampling size (e.g., 300 points instead of 1200)\n",
    "DOWNSAMPLE_SIZE = 300\n",
    "\n",
    "# Downsample all trajectories\n",
    "sim_ds = np.apply_along_axis(downsample_trajectory, 2, results[0], DOWNSAMPLE_SIZE)\n",
    "obs_ds = np.apply_along_axis(downsample_trajectory, 2, observed, DOWNSAMPLE_SIZE)\n",
    "\n",
    "def compute_frechet(i, j):\n",
    "    return frechet_distance_dp(sim_ds[i, j, :], obs_ds[i, j, :])\n",
    "\n",
    "# Parallel computing\n",
    "start = time.time()\n",
    "frechet_distances = np.array(\n",
    "    Parallel(n_jobs=-1, backend=\"loky\")(delayed(compute_frechet)(i, j) for i in range(51) for j in range(51))\n",
    ").reshape(51, 51)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "# Aggregate results\n",
    "max_distance = np.max(frechet_distances)\n",
    "mean_distance = np.mean(frechet_distances)\n",
    "\n",
    "print(f\"Max Fréchet Distance: {max_distance}\")\n",
    "print(f\"Mean Fréchet Distance: {mean_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19fd85",
   "metadata": {},
   "source": [
    "### Hausdorff Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29dd55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def directed_hausdorff(A, B):\n",
    "    \"\"\"\n",
    "    Compute the directed Hausdorff distance from set A to set B using cKDTree for efficiency.\n",
    "    \n",
    "    Parameters:\n",
    "    A (numpy array): Set of points (N x d) where N is the number of points, and d is the dimension.\n",
    "    B (numpy array): Set of points (M x d), where M is the number of points in B.\n",
    "    \n",
    "    Returns:\n",
    "    float: The directed Hausdorff distance from A to B.\n",
    "    \"\"\"\n",
    "    # Reshape (51, 51, 1200) -> (2601, 1200)\n",
    "    A_flat = A.reshape(-1, A.shape[-1])  # (2601, 1200)\n",
    "    B_flat = B.reshape(-1, B.shape[-1])  # (2601, 1200)\n",
    "    \n",
    "    tree_B = cKDTree(B_flat)  # Build KD-tree for set B\n",
    "    dists_A_to_B, _ = tree_B.query(A_flat)  # Find nearest neighbor distances for A to B\n",
    "    cmax_A_to_B = np.max(dists_A_to_B)  # Maximum of minimum distances\n",
    "    \n",
    "    tree_A = cKDTree(A_flat)  # Build KD-tree for set A\n",
    "    dists_B_to_A, _ = tree_A.query(B_flat)  # Find nearest neighbor distances for B to A\n",
    "    cmax_B_to_A = np.max(dists_B_to_A)  # Maximum of minimum distances\n",
    "    \n",
    "    return max(cmax_A_to_B, cmax_B_to_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94c4a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.81630277633667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "hausdorff_distance = Parallel(n_jobs=num_cores)(\n",
    "    delayed(directed_hausdorff)(results[i], observed)\n",
    "    for i in range(n)\n",
    ")\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0be3b69-a01e-4f91-85c9-eca281e38c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.19378979,  3.74692256, -1.94420053, ..., -2.68160491,\n",
       "       -8.7056667 ,  9.34314421])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "cx, cy, s = rng.uniform(-10, 10, (3, 100000))\n",
    "cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b64b6e-a807-4756-ac9f-3ef48120985c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0 is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m temp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/constant/run1.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtemp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:263\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '0 is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "temp = np.load(\"runs/constant/run1.npz\")\n",
    "temp[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
